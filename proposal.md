# Initial Proposal

> Please remember to rename each subtitle 

## What to do/brief introduction: research on Frame Interpolation and a demo - Lin 
    - description
    - diagram  

## How it is related to Deep Learning for CV ...  - Qiming  

## Steps 
    - research paper 
    - dataset 
    - env/demo (implementation) 
    - results analasys
There are several steps towards making the project. First, We are going to read some related articles and look into previous works on video frame interpolation. We are currently working on bring tradition video coding algorithms into this project, and adapt them into machine learning algorithms. Then, we can decide which approach we are going to take to prediction inter-frame images.  
Second, we need to decide which dataset we are going to use to train and test the neural network. Since we plan to convert lower FPS videos to 60FPS or 90FPS, we need to find some native 60FPS and 90 FPS video or corresponding picture frames.  
In addition, we are going to implement our method and develop a demo for quantitative analysis and class presentation. At this moment, we decide to build the project using Keras library on Ubuntu 18.04.  
Finally, we will run own experiment demo againt exsting project/research, such as Sepconv Slomo. Mstrics including MSE, RMSE, PSNR, and SSIM will be used to quantify the results and evaluate the performance.
 

## Schedule
    - important dates
For the project schedule, we have planned the following dates and events at this moment. However, schedule may be slightly changed in the future according to the circumstances.
- April 23 (Thursday): Meeting and review on initial proposal
- April 27 (Monday): Initial proposal due
- April 30 (Thursday): Finish reading Chapter 6, 10, and 11 of the textbook. Daniel and Wang should finish reading the DAIN and Sepconv Slomo article and present it to the rest of the group
- May 4 (Monday): Meeting on final proposal 
- May 7 (Thursday): Meeting and review on final proposal
- May 11 (Monday): Final proposal due
- May 23 (Saturday): Final code review
- May 26 (Tuesday): Final report review
- May 30 (Saturday): Presentation rehearsal
- June 1 (Monday): Presentation


## Results and Metrics

## Results:
We use our interpolation model to process the input videos with frame rate 24/25 fps to generate new videos with increased frame rate 60 and 90 fps. And the input videos are from a wide variety of video datasets with different resolutions.

1. Vimeo90K

2. UCF101

3. HD

4. Middlebury dataset

## Evaluation and Metrics:
To evaluate our interpolation model, the result videos are compared with other methods:

1. ToFlow

2. MDP-Flow2

3. AdaConv

The metrics used for the evaluation consist of quantitative and qualitative comparisons

- Quantitative Comparisons:

  - model parameters
  
  - runtime
  
  - MSE: Mean squared error
  
  - RMSE: Root-mean-square error, the square root of the mean squared error
  
  - PSNR: Peak signal-to-noise ratio, the ratio between the maximum possible power of a signal and the power of corrupting noise that affects the fidelity of its representation.
  
  - SSIM: Structural similarity (SSIM) index is a method for predicting the perceived quality of various kinds of digital images and video. It is used for measuring the similarity between two images.
- Qualitative Comparisons:
  Visual comparison based the image quality like the clear shape and the restored details.

## Risks

In some cases the results generated by this method contains blocks of noise pixels which appears like artificial spots.

## Reference  
- Niklaus, S., Mai, L., & Liu, F. (2017). Video frame interpolation via adaptive separable convolution. In IEEE International Conference on Computer Vision (pp. 261-270).
- Bao, W., Lai, W. S., Ma, C., Zhang, X., Gao, Z., & Yang, M. H. (2019). Depth-aware video frame interpolation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 3703-3712).
